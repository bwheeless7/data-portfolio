{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7d8KzL2UgyXl06KetCdDa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Z4bmvQy9O6Yv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767462330736,"user_tz":300,"elapsed":25373,"user":{"displayName":"Brian BA Baracus","userId":"03930224190383028880"}},"outputId":"eaffd184-66f1-453d-d75d-f2b3b5d8eb7b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"f8HjbwlCOrxq","executionInfo":{"status":"ok","timestamp":1767462338175,"user_tz":300,"elapsed":714,"user":{"displayName":"Brian BA Baracus","userId":"03930224190383028880"}}},"outputs":[],"source":["!git config --global user.email \"wheelessbrian@yahoo.com\"\n","!git config --global user.name \"bwheeless7\""]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/data-portfolio"],"metadata":{"id":"KC18cnvbP4n5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767462335135,"user_tz":300,"elapsed":338,"user":{"displayName":"Brian BA Baracus","userId":"03930224190383028880"}},"outputId":"6f1242bb-1423-4ba2-c258-348c10f9a7d3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data-portfolio\n"]}]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Colab Notebooks/02_modeling_and_optimization.ipynb\" /content/drive/MyDrive/data-portfolio/churn-retention-analysis/notebooks/"],"metadata":{"id":"GFVUBtpUPldh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PEESC8Kj1HB","executionInfo":{"status":"ok","timestamp":1767371689902,"user_tz":300,"elapsed":104,"user":{"displayName":"Brian BA Baracus","userId":"03930224190383028880"}},"outputId":"86f1b11c-59a7-49ac-f9de-4b3bda2a77fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["churn-retention-analysis  .git\n"]}]},{"cell_type":"code","source":["# !git add .\n","# !git commit -m \"Churn Modeling and Opimization\"\n","!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwkC3ncWilKe","executionInfo":{"status":"ok","timestamp":1767371799678,"user_tz":300,"elapsed":5123,"user":{"displayName":"Brian BA Baracus","userId":"03930224190383028880"}},"outputId":"3c3c7f0a-9c3c-4dec-c184-060138e23c88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 1\rEnumerating objects: 13, done.\n","Counting objects:   7% (1/13)\rCounting objects:  15% (2/13)\rCounting objects:  23% (3/13)\rCounting objects:  30% (4/13)\rCounting objects:  38% (5/13)\rCounting objects:  46% (6/13)\rCounting objects:  53% (7/13)\rCounting objects:  61% (8/13)\rCounting objects:  69% (9/13)\rCounting objects:  76% (10/13)\rCounting objects:  84% (11/13)\rCounting objects:  92% (12/13)\rCounting objects: 100% (13/13)\rCounting objects: 100% (13/13), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (8/8), done.\n","Writing objects: 100% (8/8), 263.70 KiB | 2.04 MiB/s, done.\n","Total 8 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To https://github.com/bwheeless7/data-portfolio.git\n","   9405a1f..4d59a94  main -> main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n"]}]},{"cell_type":"markdown","source":["# Churn Modeling & Optimization\n","\n","### Objective\n","This notebook focuses on strengthening model performance and reliability through:\n","- Algorithm comparison\n","- Hyperparameter tuning\n","- Cross-validation\n","- Business-driven model selection\n","\n","The goal is to deliver a robust, explainable churn prediction system that maximizes business value by accurately identifying customers at risk of attrition.\n"],"metadata":{"id":"44p7Q5auQY9M"}},{"cell_type":"markdown","source":["## Data Loading & Preprocessing\n","\n","We reuse the cleaned dataset and preprocessing pipeline developed in the previous notebook to ensure consistency and reproducibility across the analysis.\n"],"metadata":{"id":"ZFd7CrkxQwfU"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/data-portfolio/churn-retention-analysis/data/cleaned_churn_data.csv\")\n","\n","X = df.drop(\"Attrition_Flag\", axis=1)\n","y = df[\"Attrition_Flag\"]\n"],"metadata":{"id":"X7rUSfIDQ0BL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Comparison\n","\n","We evaluate multiple classification algorithms to identify the best performing approach for churn prediction:\n","- Logistic Regression\n","- Random Forest\n","- Gradient Boosting\n"],"metadata":{"id":"12TxkpGpW6rC"}},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import roc_auc_score\n","\n","# Define features\n","num_features = X.select_dtypes(include=\"number\").columns\n","cat_features = X.select_dtypes(exclude=\"number\").columns\n","\n","# Shared preprocessing\n","preprocess = ColumnTransformer([\n","    (\"num\", StandardScaler(), num_features),\n","    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n","])\n","\n","# Models\n","models = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n","    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n","    \"XGBoost\": XGBClassifier(\n","        eval_metric=\"logloss\",\n","        use_label_encoder=False,\n","        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum()\n","    )\n","}\n","\n","results = {}\n","\n","for name, clf in models.items():\n","    pipe = Pipeline([\n","        (\"preprocess\", preprocess),\n","        (\"classifier\", clf)\n","    ])\n","\n","    pipe.fit(X_train, y_train)\n","    preds = pipe.predict_proba(X_test)[:, 1]\n","    auc = roc_auc_score(y_test, preds)\n","\n","    results[name] = auc\n","\n","results\n"],"metadata":{"id":"BQMYy3gJXHZX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## XGBoost Pipeline Construction\n","\n","Based on initial performance, XGBoost is selected as the primary modeling framework.\n","A unified pipeline is constructed to combine preprocessing and model training, ensuring that transformations are consistently applied during cross-validation and inference."],"metadata":{"id":"mjoyHV31--SM"}},{"cell_type":"code","source":["# XG Boost Pipeline\n","\n","from xgboost import XGBClassifier\n","from sklearn.pipeline import Pipeline\n","\n","xgb_model = XGBClassifier(\n","    objective=\"binary:logistic\",\n","    eval_metric=\"auc\",\n","    use_label_encoder=False,\n","    random_state=42\n",")\n","\n","xgb_pipe = Pipeline([\n","    (\"preprocess\", preprocess),\n","    (\"classifier\", xgb_model)\n","])\n"],"metadata":{"id":"wDEu-hA-ahAs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter Optimization\n","\n","We tune the top-performing model using randomized search with cross-validation to improve generalization while controlling overfitting.\n","\n","The objective is to identify the optimal balance between model complexity and predictive performance.\n"],"metadata":{"id":"sVGnyUhzZjeh"}},{"cell_type":"code","source":["# Model Tuning\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","param_grid = {\n","    \"classifier__n_estimators\": [200, 300, 500],\n","    \"classifier__max_depth\": [3, 5, 7],\n","    \"classifier__learning_rate\": [0.01, 0.05, 0.1],\n","    \"classifier__subsample\": [0.8, 1.0],\n","    \"classifier__colsample_bytree\": [0.8, 1.0],\n","    \"classifier__gamma\": [0, 1, 5]\n","}\n","\n","search = RandomizedSearchCV(\n","    xgb_pipe,\n","    param_distributions=param_grid,\n","    n_iter=20,\n","    scoring=\"roc_auc\",\n","    cv=3,\n","    verbose=1,\n","    n_jobs=-1,\n","    random_state=42\n",")\n","\n","search.fit(X_train, y_train)\n","\n","search.best_params_, search.best_score_\n"],"metadata":{"id":"UDVtTFqcZvWL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Model Performance\n","\n","After tuning, the optimized XGBoost model achieves:\n","\n","* ROC-AUC ≈ 0.99\n","\n","This indicates excellent discrimination between churn and non-churn customers and confirms strong generalization on unseen data."],"metadata":{"id":"F7wdQumU_i7l"}},{"cell_type":"code","source":["# Train Optimized Model\n","best_xgb = search.best_estimator_\n","\n","probs_tuned = best_xgb.predict_proba(X_test)[:, 1]\n","roc_auc_score(y_test, probs_tuned)\n"],"metadata":{"id":"K7pJFGwzbDwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Business-Driven Threshold Optimization\n","\n","After training and tuning the final model, we selected a classification threshold optimized for retention objectives.  \n","Rather than using the default 0.50 cutoff, the threshold was adjusted to prioritize correctly identifying customers at risk of churn, while preserving strong overall model accuracy."],"metadata":{"id":"mMnQjcOXdyuB"}},{"cell_type":"markdown","source":["### Final Classification Performance\n","\n","At the optimized threshold, the model achieves the following performance on the test set:\n","\n","- **Overall Accuracy:** 96%\n","- **Churn Recall:** 80%  \n","- **Churn Precision:** 97%\n","- **ROC-AUC:** ~0.99\n","\n","This balance ensures that the majority of high-risk customers are detected while minimizing unnecessary outreach to low-risk customers.\n"],"metadata":{"id":"0o5c_vX6g6Xh"}},{"cell_type":"code","source":["# Plot Precision/Recall vs Threshold\n","\n","from sklearn.metrics import precision_recall_curve\n","import matplotlib.pyplot as plt\n","\n","precision, recall, thresholds = precision_recall_curve(y_test, probs_tuned)\n","\n","plt.plot(thresholds, precision[:-1], label=\"Precision\")\n","plt.plot(thresholds, recall[:-1], label=\"Recall\")\n","plt.xlabel(\"Decision Threshold\")\n","plt.ylabel(\"Score\")\n","plt.title(\"Precision–Recall Tradeoff\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"OooY1OfneAwA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select Business Threshold\n","\n","target_recall = 0.80\n","idx = (recall >= target_recall).nonzero()[0][-1]\n","optimal_threshold = thresholds[idx]\n","optimal_threshold\n"],"metadata":{"id":"UG0a9lZ2eK37"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Business Interpretation\n","\n","- **80% of churners are successfully identified**, allowing the company to intervene before cancellation.\n","- **High precision (97%)** ensures retention resources are focused on customers who truly need attention.\n","- This tradeoff delivers strong operational efficiency with minimal wasted spend.\n"],"metadata":{"id":"oZOV4KBKhPah"}},{"cell_type":"code","source":["# Evaluate at This Threshold\n","\n","from sklearn.metrics import classification_report\n","\n","preds_adj = (probs_tuned >= optimal_threshold).astype(int)\n","print(classification_report(y_test, preds_adj))\n"],"metadata":{"id":"LptAksK3eb0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Feature Importance & Key Churn Drivers\n","\n","The model reveals that customer engagement and transaction behavior are the dominant drivers of churn risk.\n","The most influential predictors are shown below.\n"],"metadata":{"id":"CXm7Pr1yhlkt"}},{"cell_type":"code","source":["# Feature Importance Interpretability\n","\n","xgb_model = best_xgb.named_steps[\"classifier\"]\n","\n","importances = pd.DataFrame({\n","    \"Feature\": best_xgb.named_steps[\"preprocess\"].get_feature_names_out(),\n","    \"Importance\": xgb_model.feature_importances_\n","}).sort_values(by=\"Importance\", ascending=False)\n","\n","importances.head(15)\n"],"metadata":{"id":"4QxDLLIQejl2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Top Predictive Signals\n","\n","The strongest churn drivers include:\n","\n","1. **Total Transaction Count**\n","2. **Total Revolving Balance**\n","3. **Total Relationship Count**\n","4. **Total Transaction Amount**\n","5. **Change in Transaction Count (Q4 vs Q1)**\n","6. **Months Inactive**\n","7. **Contact Frequency (Last 12 Months)**\n","8. **Credit Utilization & Available Credit**\n","9. **Customer Age**\n","10. **Income Category & Card Type**\n","\n","These features collectively describe customer engagement, financial behavior, and product utilization — the core levers of retention.\n"],"metadata":{"id":"S3HixR4kh0pL"}},{"cell_type":"markdown","source":["### Strategic Insight\n","\n","Customers exhibiting declining transaction activity, reduced engagement, increasing inactivity, or lower relationship depth show significantly higher churn risk.  \n","This confirms that **behavioral disengagement precedes churn**, providing a measurable early warning system.\n"],"metadata":{"id":"Qzjqhkw-h3oC"}},{"cell_type":"markdown","source":["## Translating Insights into Retention Strategy\n","\n","Using the model’s predictions and churn drivers, the business can implement targeted retention actions:\n","\n","### 1. Engagement-Based Intervention\n","Customers with falling transaction counts or increasing inactivity should receive proactive engagement:\n","- Personalized offers\n","- Loyalty incentives\n","- Product usage education\n","\n","### 2. High-Value Risk Protection\n","Customers with high revolving balances or strong relationship depth who are flagged as high risk should be prioritized for:\n","- Dedicated retention specialists\n","- Fee waivers or account reviews\n","- Credit line adjustments\n","\n","### 3. Early Warning Monitoring\n","Continuous monitoring of transaction decline and engagement metrics enables the business to intervene **before churn occurs**, rather than reacting after cancellation.\n"],"metadata":{"id":"zd2Cgx_eh8mk"}},{"cell_type":"markdown","source":["## Executive Summary\n","\n","This project demonstrates a complete, production-ready churn analytics pipeline:\n","\n","- End-to-end data processing and feature engineering\n","- High-performance predictive modeling (ROC-AUC ≈ 0.99)\n","- Business-driven threshold optimization\n","- Explainable insights into customer behavior\n","- Actionable retention strategies aligned with business objectives\n","\n","The resulting system provides the foundation for a scalable, data-driven customer retention program.\n"],"metadata":{"id":"FLWYltAkeynj"}}]}