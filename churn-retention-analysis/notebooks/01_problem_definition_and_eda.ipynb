{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14DFeE4uhHF01U_5GDi46549mhAehFw7Z","timestamp":1766946259371}],"authorship_tag":"ABX9TyOsNhzm8g8ult4/DLFixW4B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aNLRxgNM0uk8"},"outputs":[],"source":["!git init\n","!git config --global user.email \"wheelessbrian@yahoo.com\"\n","!git config --global user.name \"bwheeless7\"\n","!git remote add origin https://github.com/bwheeless7/data-portfolio.git\n"]},{"cell_type":"code","source":["!mkdir -p churn-retention-analysis/notebooks\n","!mkdir -p churn-retention-analysis/data\n","!mkdir -p churn-retention-analysis/src\n"],"metadata":{"id":"CqQlSvWRCReQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv \"/content/01_problem_definition_and_eda.ipynb\" churn-retention-analysis/notebooks/\n"],"metadata":{"id":"mLU3xAd2Cemf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find /content -maxdepth 2 -type f"],"metadata":{"id":"Exir4XOOMWwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"s2nH8bPRxc4h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/data-portfolio/churn-retention-analysis\n","!ls -a"],"metadata":{"id":"1bWCjEoAyuJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git remote -v\n"],"metadata":{"collapsed":true,"id":"GkoKCUTszsak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.name \"bwheeless7\"\n","!git config --global user.email \"wheelessbrian@yahoo.com\"\n"],"metadata":{"id":"vuadGF0x2PPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git status\n","# !git add /content/drive/MyDrive/data-portfolio/churn-retention-analysis/notebooks/01_problem_definition_and_eda.ipynb\n","# !git commit -m \"Progress on problem definition and EDA\"\n","\n"],"metadata":{"id":"iaaflfLE1Mu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull origin main --no-rebase\n"],"metadata":{"id":"4Epzg8i1z5BI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Update notebook with new analysis\"\n","!git push"],"metadata":{"id":"v9311U8k0JK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# New Workflow\n","# !git pull\n","\n","# !git add .\n","# !git commit -m \"Tune decision \"\n","# !git push\n"],"metadata":{"id":"E8yYtoOQ59Nu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Business Problem\n","A digital bank is experiencing increased customer attrition, which directly impacts revenue and long-term growth.\n","The objective is to identify the key drivers of customer churn, build a predictive model, and propose retention strategies.\n","\n","# Success Metrics\n","- Churn Rate\n","- Retention Rate\n","- Model ROC-AUC\n","- Precision/Recall at business-selected threshold\n"],"metadata":{"id":"hHtJYhMA6f8Y"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/data-portfolio/churn-retention-analysis/data/BankChurners.csv\")\n"],"metadata":{"id":"OtkXFUZq6lBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape\n","df['Attrition_Flag'].value_counts(normalize=True)"],"metadata":{"id":"pHo-ifqS67qU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initial Findings\n","\n","- Overall churn rate is approximately **16.1%**, which is significant for a financial services business.\n","- The dataset is moderately imbalanced, so evaluation will emphasize recall, precision, and ROC-AUC over raw accuracy.\n","- Even small improvements in churn reduction could yield substantial revenue impact.\n"],"metadata":{"id":"fImQj_t97iTE"}},{"cell_type":"code","source":["df.info()\n","df.head()"],"metadata":{"id":"oRg9ZUqu7zx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.drop(columns=[\n","    'CLIENTNUM',\n","    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n","    'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'\n","])\n"],"metadata":{"id":"UndR1Ww78UjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preparation Notes\n","\n","Several columns were removed prior to modeling:\n","\n","- `CLIENTNUM` (unique identifier)\n","- Two Naive Bayes probability columns that directly leak the target variable\n","\n","These features would artificially inflate model performance and are excluded to preserve model integrity.\n"],"metadata":{"id":"KR3VwVYw8W4u"}},{"cell_type":"code","source":["df['Attrition_Flag'] = df['Attrition_Flag'].map({\n","    'Existing Customer': 0,\n","    'Attrited Customer': 1\n","})\n","\n","X = df.drop('Attrition_Flag', axis=1)\n","y = df['Attrition_Flag']\n","\n","X.shape, y.mean()\n"],"metadata":{"id":"avj-bSAT8jS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y\n",")\n","\n","X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"],"metadata":{"id":"kNS8Q_Axkm6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, roc_auc_score\n","\n","categorical_cols = X.select_dtypes(include='object').columns\n","numeric_cols = X.select_dtypes(exclude='object').columns\n","\n","preprocess = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numeric_cols),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n","    ]\n",")\n","\n","model = Pipeline(steps=[\n","    ('preprocess', preprocess),\n","    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n","])\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","y_prob = model.predict_proba(X_test)[:, 1]\n","\n","print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"id":"1rmkXqJ0liCt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Baseline Model Performance\n","\n","The baseline logistic regression model achieved:\n","\n","- **ROC-AUC: 0.921**, indicating excellent overall discrimination.\n","- **Churn Recall: 0.82**, meaning the model identifies 82% of customers who will churn.\n","- **Churn Precision: 0.53**, reflecting the tradeoff between recall and false positives.\n","- **Overall Accuracy: 85%**, though accuracy is secondary due to class imbalance.\n","\n","From a business perspective, the model is highly effective at capturing potential churners, enabling proactive retention strategies.\n"],"metadata":{"id":"YYVH_RkdmKtC"}},{"cell_type":"markdown","source":["## Tuning the Decision Threshold\n","\n","Our baseline model uses a default probability cutoff of 0.5.  \n","However, for retention efforts, we want to **maximize recall** to catch as many potential churners as possible.  \n","We will evaluate different thresholds and select the one that balances recall with acceptable precision.\n"],"metadata":{"id":"po7PBeOrrh9s"}},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, f1_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Predicted probabilities for the positive class\n","y_probs = model.predict_proba(X_test)[:,1]\n","\n","precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n","f1_scores = 2 * (precision * recall) / (precision + recall)\n","\n","# Plot F1 score vs threshold\n","plt.figure(figsize=(8,5))\n","plt.plot(thresholds, f1_scores[:-1], label='F1 Score')\n","plt.plot(thresholds, recall[:-1], label='Recall', linestyle='--')\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"Score\")\n","plt.title(\"F1 Score and Recall vs Decision Threshold\")\n","plt.legend()\n","plt.show()\n","\n","# Choose threshold for target recall ~0.8\n","target_recall = 0.8\n","idx = np.argmin(np.abs(recall - target_recall))\n","optimal_threshold = thresholds[idx]\n","print(\"Optimal threshold for target recall:\", optimal_threshold)\n","\n","# Apply threshold\n","y_pred_adjusted = (y_probs >= optimal_threshold).astype(int)\n"],"metadata":{"id":"h8frY3SSrssL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["At a decision threshold of **0.53**, the model achieves approximately **80% recall** for churn prediction.\n","\n","This means the model successfully identifies the majority of customers who are at risk of churning.  \n","Although this slightly reduces precision, the trade-off is appropriate for a retention strategy where the cost of missing a potential churner is higher than the cost of contacting a customer who would have stayed.\n"],"metadata":{"id":"N_bHksbFtfpY"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred_adjusted))"],"metadata":{"id":"3StUIfRMtlP6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After tuning the decision threshold, recall improves significantly for the churn class while maintaining acceptable overall accuracy.  \n","This aligns the model with business objectives focused on proactive customer retention.\n"],"metadata":{"id":"eRFvUqPDtyor"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import precision_score, recall_score\n","\n","thresholds_test = [0.4, 0.5, 0.53, 0.6]\n","rows = []\n","\n","for t in thresholds_test:\n","    preds = (y_probs >= t).astype(int)\n","    rows.append({\n","        \"Threshold\": t,\n","        \"Precision\": precision_score(y_test, preds),\n","        \"Recall\": recall_score(y_test, preds)\n","    })\n","\n","pd.DataFrame(rows)\n"],"metadata":{"id":"AE3T-RoOuHJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This comparison confirms that 0.53 offers the best balance between recall and precision for the bankâ€™s retention objectives."],"metadata":{"id":"ktCr8cUuuN1W"}},{"cell_type":"markdown","source":["## Feature Importance Analysis\n","\n","We use the coefficients from the logistic regression model to understand which features most strongly influence churn predictions.  \n","Positive coefficients increase the likelihood of churn, while negative coefficients decrease it.\n"],"metadata":{"id":"riuk9O2RubX1"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Get feature names after preprocessing\n","ohe = model.named_steps['preprocess'].named_transformers_['cat']\n","cat_features = ohe.get_feature_names_out()\n","\n","num_features = model.named_steps['preprocess'].transformers_[0][2]\n","\n","all_features = np.concatenate([num_features, cat_features])\n","\n","# Extract coefficients\n","coefs = model.named_steps['classifier'].coef_[0]\n","\n","importance_df = pd.DataFrame({\n","    \"Feature\": all_features,\n","    \"Coefficient\": coefs\n","}).sort_values(by=\"Coefficient\", ascending=False)\n","\n","top_positive = importance_df.head(10)\n","top_negative = importance_df.tail(10)\n","\n","# Plot\n","plt.figure(figsize=(10,6))\n","plt.barh(top_positive[\"Feature\"], top_positive[\"Coefficient\"])\n","plt.title(\"Top Features Increasing Churn Risk\")\n","plt.gca().invert_yaxis()\n","plt.show()\n","\n","top_positive, top_negative"],"metadata":{"id":"K2RZb9qdu8jf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Key Drivers of Churn\n","\n","The model identifies the following major drivers of churn:\n","\n","- **Months_Inactive_12_mon** and **Contacts_Count_12_mon** are strong behavioral indicators of disengagement.\n","- **Total_Trans_Ct** and **Total_Trans_Amt** reflect declining usage prior to churn.\n","- Certain customer segments (income level, card category, education) show elevated churn risk.\n","\n","Conversely, features such as high transaction volume and strong product relationships significantly reduce churn risk.\n","\n","Overall, the dominant pattern is **declining engagement preceding customer attrition**.\n"],"metadata":{"id":"qqDdn_cGvwrA"}},{"cell_type":"markdown","source":["## Translating Model Insights into Retention Strategy\n","\n","The model reveals a clear behavioral pattern:  \n","**customers churn when engagement drops and transactional behavior declines.**\n","\n","### Key Churn Risk Drivers\n","Customers are significantly more likely to churn when they show:\n","\n","- **High transaction amounts but declining activity** (`Total_Trans_Amt`, `Total_Trans_Ct`)\n","- **Increased inactivity** (`Months_Inactive_12_mon`)\n","- **More frequent support contact** (`Contacts_Count_12_mon`)\n","- **Premium product segments** (`Card_Category_Gold`, high income categories)\n","\n","### Protective Factors\n","Customers are less likely to churn when they exhibit:\n","\n","- **Strong multi-product relationships** (`Total_Relationship_Count`)\n","- **Consistent transaction behavior**\n","- **High revolving balances and utilization**\n","- **Blue and Silver card ownership**\n"],"metadata":{"id":"M10X1iWMxWww"}},{"cell_type":"markdown","source":["### Recommended Retention Actions\n","\n","| Risk Indicator | Business Interpretation | Targeted Retention Action |\n","|---------------|----------------------|--------------------------|\n","| Rising inactivity | Customer disengaging | Proactive re-engagement campaigns, personalized offers |\n","| Falling transaction count | Reduced product usage | Usage-based incentives, cashback or loyalty rewards |\n","| High contact frequency | Customer experiencing friction | Priority service, issue resolution outreach |\n","| Premium customers showing decline | High-value customers at risk | Dedicated relationship managers, exclusive retention offers |\n","| Low product relationship count | Weak customer attachment | Cross-sell relevant financial products |\n","\n","These actions allow the bank to intervene **before churn occurs**, prioritizing high-risk, high-value customers.\n"],"metadata":{"id":"jQBYQ5yRxjDc"}},{"cell_type":"markdown","source":["### Executive Summary\n","\n","By combining predictive modeling with interpretable insights, this churn system enables the bank to:\n","- Identify at-risk customers early\n","- Prioritize outreach based on business impact\n","- Design targeted retention programs\n","- Improve long-term customer lifetime value\n","\n","This approach transforms churn prediction from a technical model into a scalable business solution.\n"],"metadata":{"id":"gpbm8kGdxp6r"}}]}